{"cells":[{"cell_type":"markdown","source":[" # ETL Prototype\n"," Establish data processing workflow for a small subset of the data."],"metadata":{}},{"source":["import os\n","import glob\n","import psycopg2\n","import pandas as pd\n","import numpy as np\n","from pathlib import Path\n","from sql_queries import *\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":1},{"cell_type":"markdown","source":[" ## Connect to Postgres Database\n"," After connecting to the database and getting a cursor object, then drop and recreate all tables."],"metadata":{}},{"source":["conn = psycopg2.connect(\n","    \"host=127.0.0.1 dbname=sparkifydb user=student password=student\"\n",")\n","conn.set_session(autocommit=True)\n","cur = conn.cursor()\n","for sql_cmd in drop_table_queries + create_table_queries:\n","    cur.execute(sql_cmd)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":2},{"cell_type":"markdown","source":[" ## Find data files for processing\n","\n"," Use `os.walk` to find all `*.json` files under the `filepath` directory."],"metadata":{}},{"source":["# Let's apply the DRY principle and write a function to load our\n","# data.\n","\n","\n","def get_files(filepath):\n","    \"\"\"Return all JSON files under filepath as a list\"\"\"\n","    all_files = []\n","    for root, dirs, files in os.walk(filepath):\n","        files = glob.glob(os.path.join(root, \"*.json\"))\n","        for f in files:\n","            all_files.append(os.path.abspath(f))\n","\n","    return all_files\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":3},{"cell_type":"markdown","source":[" ## #1: `song` Table\n"," #### Extract Data for Song Table\n","\n"," Process `song_data` by reading in a subset of the [Million Song Dataset](http://millionsongdataset.com/) and in the process extracting data from JSON files using pandas."],"metadata":{}},{"source":["song_root_dir = Path().cwd() / \"data\" / \"song_data\"\n","song_files = get_files(song_root_dir)\n","filepath = song_files[0]\n","df = pd.read_json(filepath, lines=True)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":4},{"cell_type":"markdown","source":[" #### Insert Data into the Song Table\n","\n"," - Method 1: select columns and return as a tuple knowing that there is one song per dataframe and results in __year as typye np.int64 and duration as type np.float64__.  Pandas uses numpy to store its numeric types, so this result is expected."],"metadata":{}},{"source":["song_data = next(\n","    df[[\"song_id\", \"title\", \"artist_id\", \"year\", \"duration\"]].itertuples(\n","        index=False, name=None\n","    )\n",")\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":5},{"cell_type":"markdown","source":[" - Method 2: Select columns, select first row, get values as numpy array and convert to a list that results in __year as typye int and duration as type float__.  Inserting numpy numeric types into the database using psycopg2 causes errors, so I will use this approach.  This type conversion occurs because it is behavior of [numpy.ndarray.tolist](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.tolist.html#numpy.ndarray.tolist) upon which [pandas.Series.tolist](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.tolist.html) is based.  Mystery solved!"],"metadata":{}},{"source":["# Select and insert data into the songs table\n","song_df = df[[\"song_id\", \"title\", \"artist_id\",\n","              \"year\", \"duration\"]]\n","song_df.head()\n",""],"cell_type":"code","outputs":[{"output_type":"execute_result","data":{"text/plain":"              song_id            title           artist_id  year   duration\n0  SONHOTT12A8C13493C  Something Girls  AR7G5I41187FB4CE6C  1982  233.40363","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>song_id</th>\n      <th>title</th>\n      <th>artist_id</th>\n      <th>year</th>\n      <th>duration</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>SONHOTT12A8C13493C</td>\n      <td>Something Girls</td>\n      <td>AR7G5I41187FB4CE6C</td>\n      <td>1982</td>\n      <td>233.40363</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":6}],"metadata":{},"execution_count":6},{"source":["song_data = song_df.values[0].tolist()\n","song_data = [x if x else None for x in song_data]\n","cur.execute(song_table_insert, song_data)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":7},{"cell_type":"markdown","source":[" ## #2: `artists` Table\n"," #### Extract Data for Artist Table\n","\n"," Extract data and insert into artist table."],"metadata":{}},{"source":["artist_df = (\n","    df[\n","        [\n","            \"artist_id\",\n","            \"artist_name\",\n","            \"artist_location\",\n","            \"artist_latitude\",\n","            \"artist_longitude\",\n","        ]\n","    ]\n",")\n","artist_df.head()\n",""],"cell_type":"code","outputs":[{"output_type":"execute_result","data":{"text/plain":"            artist_id artist_name  artist_location  artist_latitude  \\\n0  AR7G5I41187FB4CE6C    Adam Ant  London, England              NaN   \n\n   artist_longitude  \n0               NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>artist_id</th>\n      <th>artist_name</th>\n      <th>artist_location</th>\n      <th>artist_latitude</th>\n      <th>artist_longitude</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AR7G5I41187FB4CE6C</td>\n      <td>Adam Ant</td>\n      <td>London, England</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":8}],"metadata":{},"execution_count":8},{"source":["artist_data = artist_df.values[0].tolist()\n","cur.execute(artist_table_insert, artist_data)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":9},{"cell_type":"markdown","source":[" # Process `log_data`\n","\n"," Now let's add the subscriber activity data to see which songs are popular."],"metadata":{}},{"source":["log_data_root = Path().cwd() / \"data\" / \"log_data\"\n","log_files = get_files(log_data_root)\n","# just read first file to test functionality\n","filepath = log_files[0]\n","df = pd.read_json(filepath, lines=True)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":10},{"cell_type":"markdown","source":[" ## #3: `time` Table\n"," #### Extract and Insert Data into Time Table\n","\n"," Find what songs user's are choosing by just considering `NextSong` records.  Then convert the `ts` timestamp column to datetime and extract columns for hour, day, week of year, month, year, and weekday (see: [Accessors](https://pandas.pydata.org/pandas-docs/stable/reference/series.html#time-series-related) [dt Accessor](https://pandas.pydata.org/pandas-docs/stable/reference/series.html#api-series-dt) that allows datetime properties to be easily accessed)."],"metadata":{}},{"source":["df = df.assign(ts=pd.to_datetime(df.ts, unit=\"ms\"))\n","df = df.loc[df.page.isin([\"NextSong\"])]\n","df = df.assign(timestamp=pd.to_datetime(df.ts, unit=\"ms\"))\n","df.timestamp = df.timestamp.dt.tz_localize(\"UTC\")\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":11},{"source":["time_df = pd.DataFrame(\n","    {\n","        \"timestamp\": df.timestamp,\n","        \"hour\": df.timestamp.dt.hour,\n","        \"day\": df.timestamp.dt.day,\n","        \"week_of_year\": df.timestamp.dt.week,\n","        \"month\": df.timestamp.dt.month,\n","        \"year\": df.timestamp.dt.year,\n","        \"weekday\": df.timestamp.dt.weekday,\n","    }\n",")\n","# Here we want native pandas datatypes, so I'll user iterrows.\n","for i, row in time_df.iterrows():\n","    cur.execute(time_table_insert, list(row))\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":12},{"source":["time_df.head()\n",""],"cell_type":"code","outputs":[{"output_type":"execute_result","data":{"text/plain":"                         timestamp  hour  day  week_of_year  month  year  \\\n0 2018-11-11 02:33:56.796000+00:00     2   11            45     11  2018   \n1 2018-11-11 02:36:10.796000+00:00     2   11            45     11  2018   \n2 2018-11-11 02:40:34.796000+00:00     2   11            45     11  2018   \n4 2018-11-11 04:36:13.796000+00:00     4   11            45     11  2018   \n5 2018-11-11 04:36:46.796000+00:00     4   11            45     11  2018   \n\n   weekday  \n0        6  \n1        6  \n2        6  \n4        6  \n5        6  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>timestamp</th>\n      <th>hour</th>\n      <th>day</th>\n      <th>week_of_year</th>\n      <th>month</th>\n      <th>year</th>\n      <th>weekday</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2018-11-11 02:33:56.796000+00:00</td>\n      <td>2</td>\n      <td>11</td>\n      <td>45</td>\n      <td>11</td>\n      <td>2018</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2018-11-11 02:36:10.796000+00:00</td>\n      <td>2</td>\n      <td>11</td>\n      <td>45</td>\n      <td>11</td>\n      <td>2018</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2018-11-11 02:40:34.796000+00:00</td>\n      <td>2</td>\n      <td>11</td>\n      <td>45</td>\n      <td>11</td>\n      <td>2018</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2018-11-11 04:36:13.796000+00:00</td>\n      <td>4</td>\n      <td>11</td>\n      <td>45</td>\n      <td>11</td>\n      <td>2018</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2018-11-11 04:36:46.796000+00:00</td>\n      <td>4</td>\n      <td>11</td>\n      <td>45</td>\n      <td>11</td>\n      <td>2018</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":13}],"metadata":{},"execution_count":13},{"cell_type":"markdown","source":[" ## #4: `users` Table\n"," #### Extract and Insert Data into Users Table\n","\n"," Every time a user plays a song they appear in the log file, so naturally there will by duplicate userId entries.  Here we remove them to create a normalized user table."],"metadata":{}},{"source":["user_df = df[[\"userId\", \"firstName\", \"lastName\", \"gender\", \"level\"]]\n","user_df = user_df.drop_duplicates(subset=\"userId\", keep=\"last\")\n","user_df.head()\n",""],"cell_type":"code","outputs":[{"output_type":"execute_result","data":{"text/plain":"   userId firstName   lastName gender level\n2      69  Anabelle    Simpson      F  free\n4      32      Lily      Burns      F  free\n5      75    Joseph  Gutierrez      M  free\n10     92     Ryann      Smith      F  free\n25     49     Chloe     Cuevas      F  free","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userId</th>\n      <th>firstName</th>\n      <th>lastName</th>\n      <th>gender</th>\n      <th>level</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>69</td>\n      <td>Anabelle</td>\n      <td>Simpson</td>\n      <td>F</td>\n      <td>free</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>32</td>\n      <td>Lily</td>\n      <td>Burns</td>\n      <td>F</td>\n      <td>free</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>75</td>\n      <td>Joseph</td>\n      <td>Gutierrez</td>\n      <td>M</td>\n      <td>free</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>92</td>\n      <td>Ryann</td>\n      <td>Smith</td>\n      <td>F</td>\n      <td>free</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>49</td>\n      <td>Chloe</td>\n      <td>Cuevas</td>\n      <td>F</td>\n      <td>free</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":14}],"metadata":{},"execution_count":14},{"source":["for i, row in user_df.iterrows():\n","    cur.execute(user_table_insert, row)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":15},{"cell_type":"markdown","source":[" ## #5: `songplays` Table\n"," #### Extract and Insert Data and Songplays Table\n","\n"," To look up song or an artist, I need the unique identifier or primary key. The log files simply have the name of the song and artist.  So, I need to do a reverse lookup up to get identifiers.\n","\n"," ```sql\n"," SELECT s.song_id, a.artist_id FROM dim_song s\n"," JOIN dim_artist a ON s.artist_id = a.artist_id\n"," WHERE s.title = %s AND a.name = %s AND s.duration = %s;\n"," ```\n","\n"," Iterating over the rows of the dataframe holding the log data.  First, I extract the find the unique identifiers, Next, I combine them with other data from the log data to insert the user's songplay activity into the `song_play` table."],"metadata":{}},{"source":["for index, row in df.iterrows():\n","\n","    # get songid and artistid from song and artist tables\n","    cur.execute(song_select, (row.song, row.artist, row.length))\n","    results = cur.fetchone()\n","\n","    if results:\n","        songid, artistid = results\n","    else:\n","        songid, artistid = None, None\n","\n","    # insert songplay record\n","    songplay_data = (\n","        row.userId,\n","        songid,\n","        artistid,\n","        row.sessionId,\n","        row.ts,\n","        row.level,\n","        row.location,\n","        row.userAgent,\n","    )\n","    cur.execute(songplay_table_insert, songplay_data)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":16},{"cell_type":"markdown","source":[" ## Close Connection to Sparkify Database"],"metadata":{}},{"source":["conn.close()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":17}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}